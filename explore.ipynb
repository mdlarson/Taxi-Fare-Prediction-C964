{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c4eb67-7aae-40b6-a58d-e58195843c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Initial data processing and summarization.'''\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load and Filter Data\n",
    "# We're only interested in trips to LaGuardia Airport,\n",
    "# so we'll create a new dataset for just those rows.\n",
    "# This reduces the dataset from ~450MB/19M rows to only ~10MB/420k rows.\n",
    "# ---\n",
    "# Trip data source: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "# Title: \"April 2024 High Volume For-Hire Vehicle Trip Records\"\n",
    "# Dataset URL: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-04.parquet\n",
    "# ---\n",
    "\n",
    "# File paths\n",
    "input_file = 'fhvhv_tripdata_2024-04.parquet'\n",
    "output_file = 'filtered.parquet'\n",
    "borough_file = 'taxi_boroughs.csv' # output of parse_taxi_zones.py\n",
    "\n",
    "# Read the Parquet file\n",
    "raw = pd.read_parquet(input_file)\n",
    "\n",
    "# Select features relevant for trip cost.\n",
    "# The sales_tax, airport_fee, and bcf (Black Car Fund)\n",
    "# add to total cost, but are a constant for each ride.\n",
    "# They are excluded based on lack of independent additive information.\n",
    "columns_to_keep = ['pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_miles', 'trip_time']\n",
    "\n",
    "# Select only trips to LGA – Taxi Zone 138, then drop the column\n",
    "filtered_data = raw.loc[raw['DOLocationID'] == 138, columns_to_keep]\n",
    "filtered_data = filtered_data.drop(columns=['DOLocationID'])\n",
    "\n",
    "# Add column for total of variable costs\n",
    "filtered_data['total_cost'] = (\n",
    "    raw['base_passenger_fare'] +\n",
    "    raw['tolls'] +\n",
    "    raw['congestion_surcharge']\n",
    ")\n",
    "\n",
    "# Read borough data\n",
    "boroughs = pd.read_csv(borough_file)\n",
    "# Merge boroughs into dataset on matching Taxi Zone number\n",
    "filtered_data = filtered_data.merge(boroughs[['OBJECTID', 'borough']], left_on='PULocationID', right_on='OBJECTID').drop(columns=['OBJECTID'])\n",
    "\n",
    "# Save to new working dataset for graphs and models to follow\n",
    "filtered_data.to_parquet(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35717a89-4323-4db4-8fc4-84f3c0bac141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Summarize Working Dataset\n",
    "data = pd.read_parquet(output_file)\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a85749-912f-4231-938d-036094c98c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "# No changes in row count after these operations.\n",
    "# Including for posterity / record of work.\n",
    "# data.dropna(inplace=True)\n",
    "# data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Transform Data\n",
    "# Bin datetimes by hour of day\n",
    "data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime']).dt.hour\n",
    "\n",
    "# Replace taxi zone numbers and borough names with T/F dummy variables\n",
    "data = pd.get_dummies(data, columns=['PULocationID', 'borough'])\n",
    "\n",
    "# Sanity Check\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b958595-2d66-43da-9b47-3523c8ef3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize Data\n",
    "# TODO: Figure out how to add tick marks to this first one\n",
    "# Distribution of total cost\n",
    "# Notable: dip at ~$15-25 range, possible impact of tolls on similar-distance trips\n",
    "# Notable: very, very long tail\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data['total_cost'], bins=90, kde=True)\n",
    "plt.title('Distribution of Fares')\n",
    "plt.xlabel('Total Cost')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "# Seeing a very very long tail!\n",
    "\n",
    "# Average cost by pickup hour\n",
    "# Notable: greater variance at night\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='pickup_datetime', y='total_cost', data=data)\n",
    "plt.title('Average Cost by Pickup Hour')\n",
    "plt.xlabel('Pickup Hour')\n",
    "plt.ylabel('Total Cost')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Average cost by borough\n",
    "# Notable: Staten Island has highest base cost due to greatest distance\n",
    "# Notable: Queens has lowest base cost due to shortest distance\n",
    "sns.catplot(x=\"total_cost\", y=\"borough\", order=['Bronx','Brooklyn','Manhattan','Queens','Staten Island'], kind=\"boxen\", data=filtered_data)\n",
    "plt.title('Average Cost by Borough')\n",
    "plt.xlabel('Borough')\n",
    "plt.ylabel('Average Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8861b9c-ae97-4106-b50e-25cb3781db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Two Models\n",
    "\n",
    "# We're predicting fares at two levels of granularity: borough and neighborhood (Taxi Zone).\n",
    "# We'll use boroughs for our simplest baseline model.\n",
    "# Then compare with the neighborhood model to see if more features improve predictive power.\n",
    "\n",
    "# Before we create models, we need to make sure each is using only the relevant features.\n",
    "# We'll identify the columns that need to be dropped.\n",
    "borough_columns = [col for col in data.columns if col.startswith('borough')]\n",
    "neighborhood_columns = [col for col in data.columns if col.startswith('PULocationID')]\n",
    "\n",
    "# Borough data should exclude the neighborhoods\n",
    "# Neighborhood data should exclude the boroughs\n",
    "borough_data = data.drop(columns=neighborhood_columns)\n",
    "neighborhood_data = data.drop(columns=borough_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3975756-3553-4682-9ada-ad00299f45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Borough Model\n",
    "\n",
    "# Prepare data\n",
    "X_borough = borough_data.drop(columns=['total_cost'])\n",
    "y_borough = borough_data['total_cost']\n",
    "\n",
    "# Split data\n",
    "X_train_borough, X_test_borough, y_train_borough, y_test_borough = train_test_split(X_borough, y_borough, test_size=0.2, random_state=38)\n",
    "\n",
    "# Display training set to verify splits\n",
    "print(X_train_borough.head())\n",
    "\n",
    "# Train the model\n",
    "rf_borough = RandomForestRegressor(random_state=38)\n",
    "rf_borough.fit(X_train_borough, y_train_borough)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_borough = rf_borough.predict(X_test_borough)\n",
    "mae_borough = mean_absolute_error(y_test_borough, y_pred_borough)\n",
    "mse_borough = mean_squared_error(y_test_borough, y_pred_borough)\n",
    "r2_borough = r2_score(y_test_borough, y_pred_borough)\n",
    "\n",
    "# Print performance summary\n",
    "print(f\"Borough Model - MAE: {mae_borough}, MSE: {mse_borough}, R²: {r2_borough}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eac71c-0724-4fee-af14-f1bfa0161b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Neighborhood Model\n",
    "\n",
    "# Prepare data\n",
    "X_neighborhood = neighborhood_data.drop(columns=['total_cost'])\n",
    "y_neighborhood = neighborhood_data['total_cost']\n",
    "\n",
    "# Split data\n",
    "X_train_neighborhood, X_test_neighborhood, y_train_neighborhood, y_test_neighborhood = train_test_split(X_neighborhood, y_neighborhood, test_size=0.2, random_state=38)\n",
    "\n",
    "# Display training set to verify splits\n",
    "print(X_train_neighborhood.head())\n",
    "\n",
    "# Train the model\n",
    "rf_neighborhood = RandomForestRegressor(random_state=38)\n",
    "rf_neighborhood.fit(X_train_neighborhood, y_train_neighborhood)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_neighborhood = rf_neighborhood.predict(X_test_neighborhood)\n",
    "mae_neighborhood = mean_absolute_error(y_test_neighborhood, y_pred_neighborhood)\n",
    "mse_neighborhood = mean_squared_error(y_test_neighborhood, y_pred_neighborhood)\n",
    "r2_neighborhood = r2_score(y_test_neighborhood, y_pred_neighborhood)\n",
    "\n",
    "# Print performance summary\n",
    "print(f\"Neighborhood Model - MAE: {mae_neighborhood}, MSE: {mse_neighborhood}, R²: {r2_neighborhood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551cff1-937e-47b5-9144-42b0c3d8a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# joblib.dump(rf, 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
